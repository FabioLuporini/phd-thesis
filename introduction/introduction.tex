\chapter{Introduction}

\section{Thesis Statement}
%We explore automated performance optimization of numerical methods based upon unstructured meshes. 

%The performance optimization of numerical methods based upon unstructured meshes is a challenging task that requires knowledge of the computational domain as well as expertise in computer architecture and software engineering. This burden can be relieved by raising the level of abstraction: applications are expressed by means of domain-specific languages, while optimization is automated through high-level compilers and run-time supports. The research productivity, with high-performance, structured, and extendible software being developed, is thus maximized.

%We exploit domain-specific languages to automate the performance optimization of numerical methods based upon unstructured meshes. 

%Maximizing the performance of numerical methods based upon unstructured meshes is a challenging task that can be relieved by raising the level of abstraction: if applications are expressed with domain-specific languages, powerful optimizations can be automated through compilers without the need for complex source code analysis. 

Maximizing the performance of numerical methods for partial differential equations is a challenging task that can be relieved by raising the level of abstraction, which remarkably simplifies the introduction of powerful optimizations via domain-specific compilers. 

\section{Overview}
In many fields such as computational fluid dynamics, computational electromagnetics and structural mechanics, phenomena are modelled by partial differential equations (PDEs). Numerical techniques, like the finite volume method and the finite element method, are widely employed to approximate solutions of these PDEs. Unstructured meshes are often used to discretize the computational domain, since they allow an accurate representation of complex geometries. The solution is sought by applying suitable numerical operations, or
kernels, to the entities of a mesh, such as edges, vertices, or cells. On standard clusters of multi-cores, typically, a kernel is executed sequentially by a process, while parallelism is achieved by partitioning the mesh and assigning each partition to a different node or process. This execution model is adopted by many real-world applications and libraries.

The time required to apply the numerical kernels is a major issue, since the equation domain needs to be discretized into an extremely large number of cells to obtain a satisfactory approximation of the PDE, possibly of the order of trillions, as in \cite{Rossinelli2013}. For example, it has been well established that mesh resolution is critical in the accuracy of numerical weather forecasts. However, operational forecast centers have a strict time limit in which to produce a forecast - 60 minutes in the case of the UK Met Office. Producing efficient kernels or making the iteration over the mesh more efficient have a direct scientific payoff in higher resolution, and therefore more accurate, forecasts. Optimizing the computational cost is a critical problem for most scientific simulations. 

This thesis shows that the use of domain-specific languages for expressing this class of numerical methods can play a fundamental role in performance optimization. In the translation of the problem specification into low-level code (e.g., C), a stack of compilers will apply sophisticated transformations. In an ideal world, these transformations would manually be written, specialized, and tuned for each application and for each architecture. However, this is often in practice unrealistic: such an approach would affect the gold rules of software engineering, including code robustness, maintainability, extendibility, separation of abstractions (an optimization may hinder the actual computation code). 

As we shall demonstrate, a performance optimization process through domain-specific compilers provides significant advantages. First, simplicity: the information captured by high-level languages and/or domain properties are now straightforwardly exploitable. This is invaluable since the analysis that a compiler would otherwise have to perform would be either too complex or practically infeasible. Second, portability: different applications, or kernels, use the same transformation pipeline. Depending on the level of sophistication of the framework, execution on heterogeneous architectures may be supported. Third, clear separation of concerns. Application specialists only focus on expressing their simulations with a notation which is possibly very close to the mathematics of textbooks, whereas the performance optimization is hidden within the lower levels of abstraction. 

\section{Summary of the Contributions}
\label{sec:contributions}
%Besides developing novel compilers theory, contributions of this thesis come in the form of tools that have been, and currently are, used to accelerate scientific computations, namely:
%\begin{itemize}
%\item \textbf{A run-time library, which can be regarded as a prototype compiler, capable of optimizing sequences of non-affine loops by fusion and automatic parallelization. The library has been used to speed up a real application for tsunami simulations as well as other representative benchmarks.}
%
%One limiting factor to the performance of unstructured mesh applications is imposed by
%the need for indirect memory accesses (e.g. \texttt{A[B[i]]}) to read and
%write data associated with the various entities of the discretized domain.
%For example, when executing a kernel that numerically computes an integral over a cell, 
%which is common in a finite element method, it may be necessary
%to read the coordinates of the adjacent vertices; this is achieved by
%using a suitable indirection array, often referred to as ``map'', that
%connects cells to vertices. The problem with indirect 
%memory accesses is that they break several hardware and compiler optimizations,
%including prefetching and standard loop blocking (or tiling). A first contribution of this thesis
%is the formalization and development of a technique, called ``generalized sparse tiling'',
%that aims at increasing data locality by fusing loops in which indirections
%are used. The challenges are 1) to determine if and how a sequence of loops can be fused,
%and 2) doing it efficiently, since the fusability analysis must be performed at
%run-time, once the maps are available (i.e. once the mesh topology has been read 
%from disk).
%
%\item \textbf{A fully-operating compiler, named COFFEE\footnote{COFFEE stands for COmpiler For FinitE Element local assembly.}, capable of optimizing numerical kernels solving partial differential equations using the finite element method. The compiler is integrated with the Firedrake system (\cite{firedrake-code}).}
%
%The second contribution, in the context of the finite element method, is about optimizing the computation of so called local element matrices, which can be responsible for a significant fraction of the overall computation run-time. This is a well-known problem, and several studies can be found in the literature, among which \citep{francis}, \citep{quadrature-olegaard}, \citep{petsc-integration-gpu}, \citep{tensor-kirby}. With respect to these studies, we propose a novel set of composable, model-aware code transformations explicitly targeting, for the first time, instruction-level parallelism - with emphasis on SIMD vectorization - and register locality. These transformations are automated in COFFEE.
%\end{itemize}

\section{Dissemination}
%The research exposed in this thesis has been disseminated in the scientific community through various channels:
%\begin{itemize}
%\item \textbf{Papers.} The following is the list of publications derived from the research activity (chronological order):
%\begin{enumerate}
%\item Strout, M.M.; Luporini, F.; Krieger, C.D.; Bertolli, C.; Bercea, G.-T.; Olschanowsky, C.; Ramanujam, J.; Kelly, P.H.J., "Generalizing Run-Time Tiling with the Loop Chain Abstraction," Parallel and Distributed Processing Symposium, 2014 IEEE 28th International , vol., no., pp.1136,1145, 19-23 May 2014
%\item Fabio Luporini, Ana Lucia Varbanescu, Florian Rathgeber, Gheorghe-Teodor Bercea, J. Ramanujam, David A. Ham, and Paul H. J. Kelly. "Cross-loop optimization of arithmetic intensity for finite element local assembly". 2014. Submitted for publication.
%\item Fabio Luporini, David A. Ham, Paul H. J. Kelly. "Optimizing Automated Finite Element Integration through Expression Rewriting and Code Specialization". 2014. To be written.
%\end{enumerate}
%\item \textbf{Talks.} Talks have been delivered at the following conferences/workshops:
%\begin{enumerate}
%\item "Generalised Sparse Tiling for Unstructured Mesh Computations in the OP2 Framework". Compilers for Parallel Computing, July 2013.
%\item "COFFEE: an Optimizing Compiler for Fintie Element Local Assembly". FEniCS Workshop, July 2014.
%\end{enumerate}
%\item \textbf{Software.} The following software is released under open source licenses.
%\begin{enumerate}
%\item COFFEE (COmpiler For Finit Element local assEmbly), the compiler described in Chapter~\ref{ch:coffee}.
%\end{enumerate}
%\end{itemize}
%, and the design of this software and results have
%been disseminated in the scientific community through publications.



\section{Thesis Outline}
\label{sec:outline}

%The plan is to structure the thesis as follows:
%
%\begin{itemize}
%\item Chapter 1: \textbf{Introduction}. This is going to be similar to the introduction presented in this LSA report.
%\item Chapter 2: \textbf{Background}. The basis for understading the contributions of the thesis will be provided. This chapter will be composed of three main sections:
%\begin{itemize}
%\item a summary of the finite element method, which is required to understand the structure of the numerical kernels optimized by COFFEE;
%\item an overview of the domain-specific languages, frameworks, methodologies, and compilers that inspired the research;
%\item a summary of contemporary multi-core architectures and compilers, including those used for the performance analysis carried out in this thesis.
%\end{itemize}
%\item Chapter 3: \textbf{Generalized Sparse Tiling with the OP2 Loop Chain Abstraction}. First contribution of the thesis. Presented in Chapter~\ref{ch:sparsetiling} of this report.
%\item Chapter 4: \textbf{Generalized Loop Fusion with the OP2 Loop Chain Abstraction.} Second contribution of the thesis. Part of the plan for the third year (see Section~\ref{sec:thirdyear}).
%\item Chapter 5: \textbf{Cross-loop Optimization of Arithmetic Intensity for Finite Element Local Assembly}. Third contribution of the thesis. Presented in Chapter~\ref{ch:lowlevelopt} of this report.
%\item Chapter 6: \textbf{Conclusions}. 
%\end{itemize}
%Note that performance evaluations of the techniques presented in Chapters 3, 4, and 5 will be included directly in these chapters.
