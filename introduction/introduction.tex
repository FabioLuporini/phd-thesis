\chapter{Introduction}

\section{Thesis Statement}
%We explore automated performance optimization of numerical methods based upon unstructured meshes. 

%The performance optimization of numerical methods based upon unstructured meshes is a challenging task that requires knowledge of the computational domain as well as expertise in computer architecture and software engineering. This burden can be relieved by raising the level of abstraction: applications are expressed by means of domain-specific languages, while optimization is automated through high-level compilers and run-time supports. The research productivity, with high-performance, structured, and extendible software being developed, is thus maximized.

%We exploit domain-specific languages to automate the performance optimization of numerical methods based upon unstructured meshes. 

%Maximizing the performance of numerical methods based upon unstructured meshes is a challenging task that can be relieved by raising the level of abstraction: if applications are expressed with domain-specific languages, powerful optimizations can be automated through compilers without the need for complex source code analysis. 

Maximizing the performance of numerical methods for partial differential equations is a challenging task that can considerably be relieved by raising the level of abstraction, through which automated optimization becomes possible. 

\section{Overview}
In many fields such as computational fluid dynamics, computational electromagnetics and structural mechanics, phenomena are modelled by partial differential equations (PDEs). Numerical techniques, like the finite volume method and the finite element method, are widely employed to approximate solutions of these PDEs. Unstructured meshes are often used to discretize the computational domain, since they allow an accurate representation of complex geometries. The solution is sought by applying suitable numerical operations, or kernels, to the entities of a mesh, such as edges, vertices, or cells. On standard clusters of multi-cores, typically, a kernel is executed sequentially by a process, while parallelism is achieved by partitioning the mesh and assigning each partition to a different node or process. This execution model is adopted by many real-world applications and frameworks.

The time required to apply the numerical kernels is a major issue, since the equation domain needs to be discretized into an extremely large number of cells to obtain a satisfactory approximation of the PDE, possibly of the order of trillions, as in \cite{Rossinelli2013}. For example, it has been well established that mesh resolution is critical in the accuracy of numerical weather forecasts. However, operational forecast centers have a strict time limit in which to produce a forecast - 60 minutes in the case of the UK Met Office. Producing efficient kernels or making the iteration over the mesh more efficient have a direct scientific payoff in higher resolution, and therefore more accurate, forecasts. Optimizing the computational cost is a critical problem for most scientific simulations.

This thesis shows that the use of domain-specific languages for expressing a class of numerical methods based on unstructured meshes plays a fundamental role in performance optimization. In the translation of the problem specification into low level code (e.g., C), a stack of compilers applies sophisticated transformations. In an ideal world, these transformations would manually be written, specialized, and tuned for each application and for each architecture. However, this is often unrealistic. Indeed, such an approach affects many gold rules of software engineering, including maintainability, extendibility, and modularity.

As we shall demonstrate, a optimizing applications through domain-specific compilers has significant advantages. First, simplicity: program structure and domain properties are captured by the high level syntax, which invaluably simplifies the analysis phase in a compiler. Second, portability: multiple applications use the same transformation pipeline and execution on heterogeneous architectures may be supported. Third, separation of concerns. Application specialists focus on expressing simulations with a notation close to the mathematics of textbooks, whereas performance optimization is hidden in the lower abstraction layers. 

\section{Thesis Outline and Contributions}
\label{sec:contributions}
This thesis investigates two main problems: (i) the generalization of a compiler transformation known as {\em sparse tiling}, whose aim is to improve data locality in arbitrary sequences of irregular loops (which arise in unstructured mesh computations); (ii) the optimization of so called {\em local assembly kernels} in finite element methods. In fact, the latter spans two research directions: (ii-a) the minimization of the operation count in {\em local assembly kernels}; (ii-b) the low-level optimization of the code resulting from (ii-a), through novel and state-of-the-art loop transformations. In both (i) and (ii), {\it automation via domain-specific compilers} is a fundamental feature of our work. The order in which these topics are covered is detailed below.

The thesis comprises 7 chapters, including the present introduction and the conclusions. Chapter~\ref{ch:background} establishes the foundation upon which our contributions will be derived. Here, the basics of the finite element method, the state-of-the-art on automated code generation for unstructured mesh computations, and compiler optimization are reviewed. Chapters~\ref{ch:sparsetiling},~\ref{ch:optimality}, and~\ref{ch:lowlevelopt}, which respectively correspond to the aforementioned research topics (i), (ii-a), and (ii-b), represent the core contributions of this thesis. In particular:

\begin{description}
\item[Chapter~\ref{ch:sparsetiling}] Sparse tiling is a transformation that fuses and tiles loops characterized by indirect memory accesses (e.g., {\tt A[B[i]]}). These loops are common when iterating over unstructured meshes. The research on sparse tiling can logically be split into two phases:
\begin{enumerate}
\item The initial work was a joint international effort with people from several institutions: Michelle M. Strout, Christopher Krieger, and Catherine Olschanowsky (Colorado State University; fundamental contributions to the first version of the {\em generalized sparse tiling algorithm} for shared-memory architectures); Carlo Bertolli (IBM T. J. Watson; main algorithm and debugging); J. ``Ram'' Ramanujam (Louisiana State University; main algorithm); Gheorghe-Teodor Bercea and Paul H. J. Kelly (Imperial College; main algorithm). The design and the implementation of the first sparse tiling algorithm in the OP2 library were entirely performed by the author of this thesis. 
\item The work has later been extended in three directions: a more efficient sparse tiling algorithm for shared-memory execution; support for distributed-memory execution (with contributions from Michael Lange); automation in the Firedrake framework through the SLOPE library. SLOPE implements sparse tiling, and is entirely a by-product of this thesis.
\end{enumerate}

\item[Chapter~\ref{ch:optimality}] An algorithm for minimizing the operation count in a class of finite element integration loop nests is devised and evaluated. This algorithm, which exploits fundamental mathematical properties of finite element operators, is proven to achieve a locally optimal operation count. Rewrite operators, such as factorization and generalized loop-invariant code motion, as well as cost models are to this purpose used. The algorithm is implemented in COFFEE, a domain-specific compiler conceived and written by the author of this thesis. COFFEE is integrated in the Firedrake system, which is capable of solving PDEs expressed in mathematical syntax through the finite element method. As such, the technology developed in this chapter is used in a number of projects built on top of Firedrake.

\item[Chapter~\ref{ch:lowlevelopt}] The low level optimization of the code resulting from the minimization algorithm in Chapter~\ref{ch:optimality} is studied. A number of transformations, both novel (inspired by kernel structure and/or domain properties) and known (yet specialized, to take advantage of kernel properties), are introduced. SIMD vectorization and register locality on state-of-the-art CPUs are targeted. Since the implementation is carried out in COFFEE, the transformations are promptly available to Firedrake users. Some of them -- the ones which are proven to provide systematic performance improvements -- are automatically applied in the default optimization process.

\end{description}

Finally, Chapter~\ref{ch:coffee} describes the conception, architecture and interface of COFFEE. This is a technical chapter, in which implementation choices and challenges are discussed.

Summarizing, this thesis advances the state-of-the-art by introducing new performance optimizations for a class of unstructured mesh computations (with emphasis on the finite element method) and by automating them through two new software components: SLOPE and COFFEE.


\section{Dissemination}
The tools developed in this thesis are released under open source licenses. The underlying theory has been exposed to the scientific community through various publications and presentations.

\begin{description}
\item[Publications] From this thesis derive three main publications; a further publication is planned for the most recent achievements in sparse tiling. In chronological order:
\begin{description}
\item[\citep{st-paper}] This conference paper generalizes sparse tiling to arbitrary sequences of irregular loops.
\item[\citep{Luporini-coffee}] This journal paper describes the work on the low level optimization of finite element integration loops (Chapter~\ref{ch:lowlevelopt}).
\item[\citep{Luporini-minimalflops}] The operation count minimization algorithm (Chapter~\ref{ch:optimality}) is introduced in this journal article.
\end{description}
Other publications -- the result of collaborations with people at Imperial College -- are not reported here since they do not contribute directly to the achievements in this thesis.
\item[Presentations] A number of formal and informal presentations were given at various conferences, workshops, and meetings. The most relevant, in chronological order, are:
\begin{itemize}
\item Generalised Sparse Tiling for Unstructured Mesh Computations in the OP2 Framework. CPC 2013.
\item COFFEE: an Optimizing Compiler for Fintie Element Local Assembly. FEniCS 2014.
\item Optimization of Arithemtic Intensity for Finite Element Assembly. GungHo! 2014.
\item Cross-loop Optimization of Arithmetic Intensity and Data Locality for Unstructured Mesh Applications. Oxford Many-core seminars, 2014.
\item Cross-loop Optimization of Arithmetic Intensity for Finite Element Local Assembly. HiPEAC (main track), 2015.
\item Generating high performance finite element kernels using optimality criteria. SIAM PP 2016.
\item An algorithm for the optimization of finite element integration loops. PRISM Workshop (Imperial College) 2016.
\end{itemize}
\end{description}


