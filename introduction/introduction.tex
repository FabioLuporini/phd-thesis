\chapter{Introduction}

\section{Thesis Statement}
%Computational efficiency in real-world unstructured-mesh-based applications requires specialized sequential code and execution models optimized for non-affine loops. We advocate and demonstrate that an approach centered on domain-specific languages, automated code generation and generalized (i.e. computation-independent) techniques for data locality and parallelism allows achieving this goal and scientists abstracting from the performance optimization problem, which is the key to software productivity.

\section{Overview}
%In many fields such as computational fluid dynamics, computational electromagnetics and structural mechanics, phenomena are modelled by partial differential equations (PDEs). Numerical techniques, like the finite volume method and the finite element method, are widely employed to approximate solutions of these PDEs. Unstructured meshes are often used to discretize the computational domain, since they allow an accurate representation of complex geometries. The solution is sought by applying suitable numerical operations, or
%kernels, to the entities of a mesh, such as edges, vertices, or cells. On standard clusters of multicores, typically, a kernel is executed sequentially by a thread, while parallelism is achieved by partitioning the mesh and assigning each partition to a different node or thread. Such an execution model, with minor variations, is adopted, for example, in \cite{pyop2isc}, \cite{Fenics}, \cite{fluidity_manual_v4}, \cite{lizst}.
%
%The time required to apply the numerical kernels is a major issue, since the equation domain needs to be discretized into an extremely large number of cells to obtain a satisfactory approximation of the PDE, possibly of the order of trillions, as in \cite{Rossinelli2013}. For example, it has been well established that mesh resolution is critical in the accuracy of numerical weather forecasts. However, operational forecast centers have a strict time limit in which to produce a forecast - 60 minutes in the case of the UK Met Office. Producing efficient kernels has a direct scientific payoff in higher resolution, and therefore more accurate, forecasts. Computational cost is a dominant problem in computational science simulations, especially for those based on finite elements, which are the subject of this work. In this chapter, we address, in particular, the well-known problem of optimizing the local assembly phase of the finite element method, which can be responsible for a significant fraction of the overall computation run-time, often in the range 30-60$\%$ \citep{francis}, \citep{quadrature-olegaard}, \citep{petsc-integration-gpu}, \citep{tensor-kirby}. 
%
%During the assembly phase, the solution of the PDE is approximated by executing a problem-specific kernel over all cells, or elements, in the discretized domain. We restrict our focus to relatively low order finite element methods, in which an assembly kernel's working set is usually small enough to fit the L1 cache. Low order methods are by no means exotic: they are employed in a wide variety of fields, including climate and ocean modeling, computational fluid dynamics, and structural mechanics. The efficient assembly of high order methods such as the spectral element method \citep{spencer} requires a significantly different loop nest structure. High order methods are therefore excluded from our study.

%In many fields, such as computational fluid dynamics, computational
%electromagnetics and structural mechanics, phenomena are modelled by
%partial differential equations (PDEs). Unstructured meshes, which
%allow an accurate representation of complex geometries, are often used 
%to discretize their computational domain. Numerical techniques, like the
%finite volume method and the finite element method, approximate the solution 
%of a PDE by applying suitable numerical operations, or kernels, to the 
%various entities of the unstructured mesh, such as edges, vertices, or
%cells. On standard clusters of multicores, typically, a kernel is
%executed sequentially by a thread, while parallelism is achieved by
%partitioning the mesh and assigning each partition to a different node
%or thread. Such an execution model, with minor variations, is adopted,
%for instance, in \cite{pyop2isc}, \cite{Fenics}, \cite{fluidity_manual_v4}, \cite{lizst}, which
%are examples of frameworks specifically thought for writing numerical methods for PDEs.
%
%The time required to execute these unstructured-mesh-based applications is a fundamental issue.
%An equation domain needs to be discretized into an extremely
%large number of cells to obtain a satisfactory approximation
%of the solution, possibly of the order of trillions
%(e.g. \cite{Rossinelli2013}), so applying numerical kernels all over the mesh is expensive. 
%For example, it is well-established that mesh resolution is crucial in the accuracy of numerical weather
%forecasts; however, operational centers have a strict time
%limit in which to produce a forecast - 60 minutes in the case of the
%UK Met Office - so, executing computation- and memory-efficient 
%kernels has a direct scientific payoff in higher resolution, and 
%therefore more accurate predictions. Motivated by this and analogous scenarios, 
%this thesis studies, formalizes, and implements a number of
%code transformations to improve the performance of real-world scientific 
%applications using numerical methods over unstructured meshes. 

\section{Contributions}
\label{sec:contributions}
%Besides developing novel compilers theory, contributions of this thesis come in the form of tools that have been, and currently are, used to accelerate scientific computations, namely:
%\begin{itemize}
%\item \textbf{A run-time library, which can be regarded as a prototype compiler, capable of optimizing sequences of non-affine loops by fusion and automatic parallelization. The library has been used to speed up a real application for tsunami simulations as well as other representative benchmarks.}
%
%One limiting factor to the performance of unstructured mesh applications is imposed by
%the need for indirect memory accesses (e.g. \texttt{A[B[i]]}) to read and
%write data associated with the various entities of the discretized domain.
%For example, when executing a kernel that numerically computes an integral over a cell, 
%which is common in a finite element method, it may be necessary
%to read the coordinates of the adjacent vertices; this is achieved by
%using a suitable indirection array, often referred to as ``map'', that
%connects cells to vertices. The problem with indirect 
%memory accesses is that they break several hardware and compiler optimizations,
%including prefetching and standard loop blocking (or tiling). A first contribution of this thesis
%is the formalization and development of a technique, called ``generalized sparse tiling'',
%that aims at increasing data locality by fusing loops in which indirections
%are used. The challenges are 1) to determine if and how a sequence of loops can be fused,
%and 2) doing it efficiently, since the fusability analysis must be performed at
%run-time, once the maps are available (i.e. once the mesh topology has been read 
%from disk).
%
%\item \textbf{A fully-operating compiler, named COFFEE\footnote{COFFEE stands for COmpiler For FinitE Element local assembly.}, capable of optimizing numerical kernels solving partial differential equations using the finite element method. The compiler is integrated with the Firedrake system (\cite{firedrake-code}).}
%
%The second contribution, in the context of the finite element method, is about optimizing the computation of so called local element matrices, which can be responsible for a significant fraction of the overall computation run-time. This is a well-known problem, and several studies can be found in the literature, among which \citep{francis}, \citep{quadrature-olegaard}, \citep{petsc-integration-gpu}, \citep{tensor-kirby}. With respect to these studies, we propose a novel set of composable, model-aware code transformations explicitly targeting, for the first time, instruction-level parallelism - with emphasis on SIMD vectorization - and register locality. These transformations are automated in COFFEE.
%\end{itemize}

\section{Dissemination}
%The research exposed in this thesis has been disseminated in the scientific community through various channels:
%\begin{itemize}
%\item \textbf{Papers.} The following is the list of publications derived from the research activity (chronological order):
%\begin{enumerate}
%\item Strout, M.M.; Luporini, F.; Krieger, C.D.; Bertolli, C.; Bercea, G.-T.; Olschanowsky, C.; Ramanujam, J.; Kelly, P.H.J., "Generalizing Run-Time Tiling with the Loop Chain Abstraction," Parallel and Distributed Processing Symposium, 2014 IEEE 28th International , vol., no., pp.1136,1145, 19-23 May 2014
%\item Fabio Luporini, Ana Lucia Varbanescu, Florian Rathgeber, Gheorghe-Teodor Bercea, J. Ramanujam, David A. Ham, and Paul H. J. Kelly. "Cross-loop optimization of arithmetic intensity for finite element local assembly". 2014. Submitted for publication.
%\item Fabio Luporini, David A. Ham, Paul H. J. Kelly. "Optimizing Automated Finite Element Integration through Expression Rewriting and Code Specialization". 2014. To be written.
%\end{enumerate}
%\item \textbf{Talks.} Talks have been delivered at the following conferences/workshops:
%\begin{enumerate}
%\item "Generalised Sparse Tiling for Unstructured Mesh Computations in the OP2 Framework". Compilers for Parallel Computing, July 2013.
%\item "COFFEE: an Optimizing Compiler for Fintie Element Local Assembly". FEniCS Workshop, July 2014.
%\end{enumerate}
%\item \textbf{Software.} The following software is released under open source licenses.
%\begin{enumerate}
%\item COFFEE (COmpiler For Finit Element local assEmbly), the compiler described in Chapter~\ref{ch:coffee}.
%\end{enumerate}
%\end{itemize}
%, and the design of this software and results have
%been disseminated in the scientific community through publications.



\section{Thesis Outline}
\label{sec:outline}

%The plan is to structure the thesis as follows:
%
%\begin{itemize}
%\item Chapter 1: \textbf{Introduction}. This is going to be similar to the introduction presented in this LSA report.
%\item Chapter 2: \textbf{Background}. The basis for understading the contributions of the thesis will be provided. This chapter will be composed of three main sections:
%\begin{itemize}
%\item a summary of the finite element method, which is required to understand the structure of the numerical kernels optimized by COFFEE;
%\item an overview of the domain-specific languages, frameworks, methodologies, and compilers that inspired the research;
%\item a summary of contemporary multi-core architectures and compilers, including those used for the performance analysis carried out in this thesis.
%\end{itemize}
%\item Chapter 3: \textbf{Generalized Sparse Tiling with the OP2 Loop Chain Abstraction}. First contribution of the thesis. Presented in Chapter~\ref{ch:sparsetiling} of this report.
%\item Chapter 4: \textbf{Generalized Loop Fusion with the OP2 Loop Chain Abstraction.} Second contribution of the thesis. Part of the plan for the third year (see Section~\ref{sec:thirdyear}).
%\item Chapter 5: \textbf{Cross-loop Optimization of Arithmetic Intensity for Finite Element Local Assembly}. Third contribution of the thesis. Presented in Chapter~\ref{ch:lowlevelopt} of this report.
%\item Chapter 6: \textbf{Conclusions}. 
%\end{itemize}
%Note that performance evaluations of the techniques presented in Chapters 3, 4, and 5 will be included directly in these chapters.
